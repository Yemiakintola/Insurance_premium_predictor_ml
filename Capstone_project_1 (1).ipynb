{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baf17f2d-ebc6-405d-8d35-a3948a9f279a",
   "metadata": {},
   "source": [
    "CAPSTONE PROJECT 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d99a29f-a966-4f40-a1c2-fcc182ea0e21",
   "metadata": {},
   "source": [
    "Task: Develop a regression model to predict the Premium amount based on the data provided.\n",
    "Objectives are:\n",
    "\n",
    "1.) Clean and preprocess the data\n",
    "\n",
    "2.) Explore feature importance and relationships\n",
    "\n",
    "3.) Build and evaluate a robust predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd50f6d-51f6-43eb-9514-db1c6810207f",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fa15558-2e4a-4144-9cce-dcafed76b48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as py\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency\n",
    "import matplotlib.patches as mpatches  # Import mpatches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d12181-f7bb-467d-9682-29504080b7f5",
   "metadata": {},
   "source": [
    "Read the dataset into pandas and preview the first five rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fcd24af-4f22-49e7-a5de-602a731195c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Number of Dependents</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Health Score</th>\n",
       "      <th>Location</th>\n",
       "      <th>Policy Type</th>\n",
       "      <th>Previous Claims</th>\n",
       "      <th>Vehicle Age</th>\n",
       "      <th>Credit Score</th>\n",
       "      <th>Insurance Duration</th>\n",
       "      <th>Premium Amount</th>\n",
       "      <th>Policy Start Date</th>\n",
       "      <th>Customer Feedback</th>\n",
       "      <th>Smoking Status</th>\n",
       "      <th>Exercise Frequency</th>\n",
       "      <th>Property Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>99990.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Master's</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.074627</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Comprehensive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>320.0</td>\n",
       "      <td>5</td>\n",
       "      <td>308.0</td>\n",
       "      <td>2022-12-10 15:21:39.078837</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Condo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2867.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.271335</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Comprehensive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>694.0</td>\n",
       "      <td>4</td>\n",
       "      <td>517.0</td>\n",
       "      <td>2023-01-31 15:21:39.078837</td>\n",
       "      <td>Good</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>30154.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.714909</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Comprehensive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16</td>\n",
       "      <td>652.0</td>\n",
       "      <td>8</td>\n",
       "      <td>849.0</td>\n",
       "      <td>2023-11-26 15:21:39.078837</td>\n",
       "      <td>Poor</td>\n",
       "      <td>No</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>48371.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>25.346926</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Comprehensive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>330.0</td>\n",
       "      <td>7</td>\n",
       "      <td>927.0</td>\n",
       "      <td>2023-02-27 15:21:39.078837</td>\n",
       "      <td>Poor</td>\n",
       "      <td>No</td>\n",
       "      <td>Rarely</td>\n",
       "      <td>Condo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>54174.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High School</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>6.659499</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Comprehensive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>303.0</td>\n",
       "      <td>2020-11-25 15:21:39.078837</td>\n",
       "      <td>Poor</td>\n",
       "      <td>No</td>\n",
       "      <td>Rarely</td>\n",
       "      <td>Condo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Gender  Annual Income Marital Status  Number of Dependents  \\\n",
       "0  56.0    Male        99990.0        Married                   1.0   \n",
       "1  46.0    Male         2867.0         Single                   1.0   \n",
       "2  32.0  Female        30154.0       Divorced                   3.0   \n",
       "3  60.0  Female        48371.0       Divorced                   0.0   \n",
       "4  25.0  Female        54174.0       Divorced                   0.0   \n",
       "\n",
       "  Education Level     Occupation  Health Score  Location    Policy Type  \\\n",
       "0        Master's            NaN     31.074627     Urban  Comprehensive   \n",
       "1      Bachelor's            NaN     50.271335     Urban  Comprehensive   \n",
       "2      Bachelor's            NaN     14.714909  Suburban  Comprehensive   \n",
       "3             PhD  Self-Employed     25.346926     Rural  Comprehensive   \n",
       "4     High School  Self-Employed      6.659499     Urban  Comprehensive   \n",
       "\n",
       "   Previous Claims  Vehicle Age  Credit Score  Insurance Duration  \\\n",
       "0              NaN           13         320.0                   5   \n",
       "1              NaN            3         694.0                   4   \n",
       "2              2.0           16         652.0                   8   \n",
       "3              1.0           11         330.0                   7   \n",
       "4              NaN            9           NaN                   8   \n",
       "\n",
       "   Premium Amount           Policy Start Date Customer Feedback  \\\n",
       "0           308.0  2022-12-10 15:21:39.078837              Poor   \n",
       "1           517.0  2023-01-31 15:21:39.078837              Good   \n",
       "2           849.0  2023-11-26 15:21:39.078837              Poor   \n",
       "3           927.0  2023-02-27 15:21:39.078837              Poor   \n",
       "4           303.0  2020-11-25 15:21:39.078837              Poor   \n",
       "\n",
       "  Smoking Status Exercise Frequency Property Type  \n",
       "0            Yes              Daily         Condo  \n",
       "1            Yes            Monthly         House  \n",
       "2             No            Monthly         House  \n",
       "3             No             Rarely         Condo  \n",
       "4             No             Rarely         Condo  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Insurance Premium Prediction Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f2fd9d-21ee-4611-83dd-8f1e879670b3",
   "metadata": {},
   "source": [
    "peep into the dataset to get basic information about the data type and column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12721ef6-b3a8-459b-91eb-0fe3401203c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 278860 entries, 0 to 278859\n",
      "Data columns (total 20 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   Age                   274175 non-null  float64\n",
      " 1   Gender                278860 non-null  object \n",
      " 2   Annual Income         264905 non-null  float64\n",
      " 3   Marital Status        273841 non-null  object \n",
      " 4   Number of Dependents  250974 non-null  float64\n",
      " 5   Education Level       278860 non-null  object \n",
      " 6   Occupation            197572 non-null  object \n",
      " 7   Health Score          268263 non-null  float64\n",
      " 8   Location              278860 non-null  object \n",
      " 9   Policy Type           278860 non-null  object \n",
      " 10  Previous Claims       197572 non-null  float64\n",
      " 11  Vehicle Age           278860 non-null  int64  \n",
      " 12  Credit Score          250974 non-null  float64\n",
      " 13  Insurance Duration    278860 non-null  int64  \n",
      " 14  Premium Amount        277019 non-null  float64\n",
      " 15  Policy Start Date     278860 non-null  object \n",
      " 16  Customer Feedback     260511 non-null  object \n",
      " 17  Smoking Status        278860 non-null  object \n",
      " 18  Exercise Frequency    278860 non-null  object \n",
      " 19  Property Type         278860 non-null  object \n",
      "dtypes: float64(7), int64(2), object(11)\n",
      "memory usage: 42.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Number of Dependents</th>\n",
       "      <th>Health Score</th>\n",
       "      <th>Previous Claims</th>\n",
       "      <th>Vehicle Age</th>\n",
       "      <th>Credit Score</th>\n",
       "      <th>Insurance Duration</th>\n",
       "      <th>Premium Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>274175.000000</td>\n",
       "      <td>264905.000000</td>\n",
       "      <td>250974.000000</td>\n",
       "      <td>268263.000000</td>\n",
       "      <td>197572.000000</td>\n",
       "      <td>278860.000000</td>\n",
       "      <td>250974.000000</td>\n",
       "      <td>278860.000000</td>\n",
       "      <td>277019.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>41.020771</td>\n",
       "      <td>42089.085329</td>\n",
       "      <td>1.998048</td>\n",
       "      <td>28.584290</td>\n",
       "      <td>0.998117</td>\n",
       "      <td>9.520283</td>\n",
       "      <td>574.362049</td>\n",
       "      <td>5.007764</td>\n",
       "      <td>966.118667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.549683</td>\n",
       "      <td>35444.517255</td>\n",
       "      <td>1.412312</td>\n",
       "      <td>15.966208</td>\n",
       "      <td>1.000795</td>\n",
       "      <td>5.767915</td>\n",
       "      <td>158.792037</td>\n",
       "      <td>2.581349</td>\n",
       "      <td>909.404567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>13588.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.149890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>437.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>286.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>32191.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>26.451244</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>575.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>688.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>62164.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.966369</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1367.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>149997.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>93.876090</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>849.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4999.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Age  Annual Income  Number of Dependents   Health Score  \\\n",
       "count  274175.000000  264905.000000         250974.000000  268263.000000   \n",
       "mean       41.020771   42089.085329              1.998048      28.584290   \n",
       "std        13.549683   35444.517255              1.412312      15.966208   \n",
       "min        18.000000       0.000000              0.000000       0.035436   \n",
       "25%        29.000000   13588.000000              1.000000      16.149890   \n",
       "50%        41.000000   32191.000000              2.000000      26.451244   \n",
       "75%        53.000000   62164.000000              3.000000      38.966369   \n",
       "max        64.000000  149997.000000              4.000000      93.876090   \n",
       "\n",
       "       Previous Claims    Vehicle Age   Credit Score  Insurance Duration  \\\n",
       "count    197572.000000  278860.000000  250974.000000       278860.000000   \n",
       "mean          0.998117       9.520283     574.362049            5.007764   \n",
       "std           1.000795       5.767915     158.792037            2.581349   \n",
       "min           0.000000       0.000000     300.000000            1.000000   \n",
       "25%           0.000000       5.000000     437.000000            3.000000   \n",
       "50%           1.000000      10.000000     575.000000            5.000000   \n",
       "75%           2.000000      15.000000     712.000000            7.000000   \n",
       "max           9.000000      19.000000     849.000000            9.000000   \n",
       "\n",
       "       Premium Amount  \n",
       "count   277019.000000  \n",
       "mean       966.118667  \n",
       "std        909.404567  \n",
       "min          0.000000  \n",
       "25%        286.000000  \n",
       "50%        688.000000  \n",
       "75%       1367.000000  \n",
       "max       4999.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea5f025-e5f3-455b-af6f-9422823062f3",
   "metadata": {},
   "source": [
    "Check for duplicates in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "714e28cf-b070-4e87-9274-9b93dd848393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicates found in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in the entire DataFrame\n",
    "duplicates = df[df.duplicated(keep=False)]  # keep=False to show all duplicate rows\n",
    "\n",
    "if not duplicates.empty:\n",
    "    print(\"Duplicates found:\")\n",
    "    display(duplicates)\n",
    "    initial_rows = df.shape[0]\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    rows_after_dropping_duplicates = df.shape[0]\n",
    "\n",
    "else:\n",
    "    print(\"No duplicates found in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9502ec8a-c838-4943-96ff-2e014e0f1c29",
   "metadata": {},
   "source": [
    "Converting column values into appropriate formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec3d8304-36b3-4f9f-9670-ca8fdb1bf157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data types:\n",
      "Age                     float64\n",
      "Gender                   object\n",
      "Annual Income           float64\n",
      "Marital Status           object\n",
      "Number of Dependents    float64\n",
      "Education Level          object\n",
      "Occupation               object\n",
      "Health Score            float64\n",
      "Location                 object\n",
      "Policy Type              object\n",
      "Previous Claims         float64\n",
      "Vehicle Age               int64\n",
      "Credit Score            float64\n",
      "Insurance Duration        int64\n",
      "Premium Amount          float64\n",
      "Policy Start Date        object\n",
      "Customer Feedback        object\n",
      "Smoking Status           object\n",
      "Exercise Frequency       object\n",
      "Property Type            object\n",
      "dtype: object\n",
      "\n",
      "Data types after conversions and formatting:\n",
      "Age                            float64\n",
      "Gender                          object\n",
      "Annual Income                  float64\n",
      "Marital Status                  object\n",
      "Number of Dependents           float64\n",
      "Education Level                 object\n",
      "Occupation                      object\n",
      "Health Score                   float64\n",
      "Location                        object\n",
      "Policy Type                     object\n",
      "Previous Claims                float64\n",
      "Vehicle Age                      int64\n",
      "Credit Score                   float64\n",
      "Insurance Duration               int64\n",
      "Premium Amount                 float64\n",
      "Policy Start Date       datetime64[ns]\n",
      "Customer Feedback               object\n",
      "Smoking Status                  object\n",
      "Exercise Frequency              object\n",
      "Property Type                   object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 1. Examine data types\n",
    "print(\"Original data types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# 2. Convert numerical columns currently as objects to numeric\n",
    "numeric_cols_to_convert = ['Annual Income', 'Premium Amount', 'Credit Score', 'Health Score', 'Previous Claims']\n",
    "for col in numeric_cols_to_convert:\n",
    "    if col in df.columns and df[col].dtype == 'object':\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# 3. Ensure consistent formatting for categorical text data\n",
    "text_cols_to_clean = ['Gender', 'Marital Status', 'Education Level', 'Occupation', 'Location', 'Policy Type', 'Customer Feedback', 'Smoking Status', 'Exercise Frequency', 'Property Type']\n",
    "for col in text_cols_to_clean:\n",
    "    if col in df.columns and df[col].dtype == 'object':\n",
    "        df[col] = df[col].str.lower().str.strip()\n",
    "\n",
    "# 4. Convert date columns to datetime objects\n",
    "date_cols_to_convert = ['Policy Start Date']\n",
    "for col in date_cols_to_convert:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "# 5. Display data types after conversions\n",
    "print(\"\\nData types after conversions and formatting:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d44cf-3b6f-41ac-a4f7-530f49af9c98",
   "metadata": {},
   "source": [
    "Understanding the percentage of missing values to the whole column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1e3132e-1782-45c4-8ce3-8152c54ec072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Count</th>\n",
       "      <th>Missing Percentage (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Occupation</th>\n",
       "      <td>81288</td>\n",
       "      <td>29.150111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Previous Claims</th>\n",
       "      <td>81288</td>\n",
       "      <td>29.150111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of Dependents</th>\n",
       "      <td>27886</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit Score</th>\n",
       "      <td>27886</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customer Feedback</th>\n",
       "      <td>18349</td>\n",
       "      <td>6.580004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual Income</th>\n",
       "      <td>13955</td>\n",
       "      <td>5.004303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health Score</th>\n",
       "      <td>10597</td>\n",
       "      <td>3.800115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marital Status</th>\n",
       "      <td>5019</td>\n",
       "      <td>1.799828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>4685</td>\n",
       "      <td>1.680055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Premium Amount</th>\n",
       "      <td>1841</td>\n",
       "      <td>0.660188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Missing Count  Missing Percentage (%)\n",
       "Occupation                    81288               29.150111\n",
       "Previous Claims               81288               29.150111\n",
       "Number of Dependents          27886               10.000000\n",
       "Credit Score                  27886               10.000000\n",
       "Customer Feedback             18349                6.580004\n",
       "Annual Income                 13955                5.004303\n",
       "Health Score                  10597                3.800115\n",
       "Marital Status                 5019                1.799828\n",
       "Age                            4685                1.680055\n",
       "Premium Amount                 1841                0.660188"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0].sort_values(ascending=False)\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "\n",
    "missing_info = pd.DataFrame({'Missing Count': missing_values, 'Missing Percentage (%)': missing_percentage})\n",
    "display(missing_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf9d23e-4f59-4434-8ad5-deecba4e220f",
   "metadata": {},
   "source": [
    "Handling the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "996ca302-c671-4b0a-b435-75225ef0a6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All missing values have been handled.\n"
     ]
    }
   ],
   "source": [
    "# Impute numerical columns with median\n",
    "numerical_cols_to_impute = ['Annual Income', 'Health Score', 'Age', 'Premium Amount', 'Credit Score', 'Number of Dependents', 'Previous Claims']\n",
    "for col in numerical_cols_to_impute:\n",
    "    if col in df.columns and df[col].isnull().any():\n",
    "        median_val = df[col].median()\n",
    "        df.fillna({col: median_val}, inplace=True)\n",
    "\n",
    "# Impute categorical columns with mode\n",
    "categorical_cols_to_impute = ['Marital Status', 'Customer Feedback', 'Occupation']\n",
    "for col in categorical_cols_to_impute:\n",
    "    if col in df.columns and df[col].isnull().any():\n",
    "        mode_val = df[col].mode()[0]\n",
    "        df.fillna(mode_val, inplace=True)\n",
    "\n",
    "# Verify that missing values have been handled\n",
    "missing_values_after = df.isnull().sum()\n",
    "missing_values_after = missing_values_after[missing_values_after > 0]\n",
    "\n",
    "if missing_values_after.empty:\n",
    "    print(\"All missing values have been handled.\")\n",
    "else:\n",
    "    print(\"Remaining missing values:\")\n",
    "    display(missing_values_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca27435-c97b-4649-a8ad-c66fc7e4ea3d",
   "metadata": {},
   "source": [
    "Identifying and handling skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02e3c9d7-1afa-4511-aea1-fd07030f2389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Skewness:\n",
      "Premium Amount          1.510386\n",
      "Previous Claims         1.204923\n",
      "Annual Income           1.061455\n",
      "Health Score            0.620481\n",
      "Number of Dependents    0.000744\n",
      "Credit Score            0.000251\n",
      "Age                    -0.001830\n",
      "Insurance Duration     -0.002477\n",
      "Vehicle Age            -0.003884\n",
      "dtype: float64\n",
      "\n",
      "Highly skewed columns (absolute skewness > 0.7):\n",
      "['Premium Amount', 'Previous Claims', 'Annual Income']\n",
      "Column 'Premium Amount' contains non-positive values, skipping Box-Cox.\n",
      "Column 'Previous Claims' contains non-positive values, skipping Box-Cox.\n",
      "Column 'Annual Income' contains non-positive values, skipping Box-Cox.\n",
      "\n",
      "Skewness after Transformations:\n",
      "Premium Amount          1.510386\n",
      "Previous Claims         1.204923\n",
      "Annual Income           1.061455\n",
      "Health Score            0.620481\n",
      "Number of Dependents    0.000744\n",
      "Credit Score            0.000251\n",
      "Age                    -0.001830\n",
      "Insurance Duration     -0.002477\n",
      "Vehicle Age            -0.003884\n",
      "Previous Claims_log    -0.092421\n",
      "Premium Amount_log     -1.099738\n",
      "Annual Income_log      -1.361367\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "# 1. Identify numerical columns\n",
    "numerical_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "# Exclude the target variable 'Premium Amount' for now if we are only transforming features\n",
    "# Depending on the modeling approach, the target variable might also need transformation,\n",
    "# but for feature skewness, we focus on predictors.\n",
    "# Let's keep 'Premium Amount' for now as it's a numerical column and its skewness might be relevant.\n",
    "\n",
    "# 2. For each numerical column, calculate its skewness.\n",
    "skewness = df[numerical_cols].skew().sort_values(ascending=False)\n",
    "print(\"Original Skewness:\")\n",
    "print(skewness)\n",
    "\n",
    "# 3. Determine a threshold for skewness\n",
    "# A common threshold is |skewness| > 1.0 for high skewness, or |skewness| > 0.5 for moderate skewness.\n",
    "# Let's use 0.7 as a threshold for transformation.\n",
    "skewness_threshold = 0.7\n",
    "highly_skewed_cols = skewness[(abs(skewness) > skewness_threshold)].index.tolist()\n",
    "\n",
    "print(f\"\\nHighly skewed columns (absolute skewness > {skewness_threshold}):\")\n",
    "print(highly_skewed_cols)\n",
    "\n",
    "# 4. Apply appropriate transformations\n",
    "transformed_df = df.copy()\n",
    "\n",
    "for col in highly_skewed_cols:\n",
    "    # Check if the column has non-negative values for log and Box-Cox transformations\n",
    "    if (transformed_df[col] >= 0).all():\n",
    "        # Apply log transformation if skewness is positive and data is non-negative\n",
    "        # Adding a small constant to handle potential zero values\n",
    "        if transformed_df[col].min() == 0:\n",
    "            transformed_df[col + '_log'] = np.log1p(transformed_df[col]) # log1p(x) = log(1+x)\n",
    "        else:\n",
    "             transformed_df[col + '_log'] = np.log(transformed_df[col])\n",
    "\n",
    "        # Apply Box-Cox transformation if skewness is positive and data is strictly positive\n",
    "        # Box-Cox requires strictly positive data.\n",
    "        # Let's check for strictly positive values before applying Box-Cox\n",
    "        if (transformed_df[col] > 0).all():\n",
    "            try:\n",
    "                transformed_df[col + '_boxcox'], fitted_lambda = boxcox(transformed_df[col])\n",
    "                print(f\"Applied Box-Cox transformation to '{col}' with lambda={fitted_lambda:.4f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Could not apply Box-Cox transformation to '{col}': {e}\")\n",
    "        else:\n",
    "             print(f\"Column '{col}' contains non-positive values, skipping Box-Cox.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Column '{col}' contains negative values, skipping log and Box-Cox transformations.\")\n",
    "        # For negative values, consider other transformations like Yeo-Johnson or simply not transforming if not severely skewed\n",
    "\n",
    "# 5. Recalculate and examine the skewness of the transformed columns\n",
    "transformed_numerical_cols = transformed_df.select_dtypes(include=np.number).columns.tolist()\n",
    "transformed_skewness = transformed_df[transformed_numerical_cols].skew().sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nSkewness after Transformations:\")\n",
    "print(transformed_skewness)\n",
    "\n",
    "# Update the original dataframe with the transformed columns\n",
    "# You might choose to keep both original and transformed columns or replace\n",
    "# For this task, let's keep the transformed columns and decide later which ones to use in modeling.\n",
    "df = transformed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1b27a0-fa30-4b60-a65d-3dd8540d9cdd",
   "metadata": {},
   "source": [
    "Encoding categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12e2da14-36d8-4370-add1-d40fdede2813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Number of Dependents</th>\n",
       "      <th>Health Score</th>\n",
       "      <th>Previous Claims</th>\n",
       "      <th>Vehicle Age</th>\n",
       "      <th>Credit Score</th>\n",
       "      <th>Insurance Duration</th>\n",
       "      <th>Premium Amount</th>\n",
       "      <th>Policy Start Date</th>\n",
       "      <th>...</th>\n",
       "      <th>Policy Type_premium</th>\n",
       "      <th>Customer Feedback_good</th>\n",
       "      <th>Customer Feedback_poor</th>\n",
       "      <th>Customer Feedback_single</th>\n",
       "      <th>Smoking Status_yes</th>\n",
       "      <th>Exercise Frequency_monthly</th>\n",
       "      <th>Exercise Frequency_rarely</th>\n",
       "      <th>Exercise Frequency_weekly</th>\n",
       "      <th>Property Type_condo</th>\n",
       "      <th>Property Type_house</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.0</td>\n",
       "      <td>99990.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.074627</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>320.0</td>\n",
       "      <td>5</td>\n",
       "      <td>308.0</td>\n",
       "      <td>2022-12-10 15:21:39.078837</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46.0</td>\n",
       "      <td>2867.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.271335</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>694.0</td>\n",
       "      <td>4</td>\n",
       "      <td>517.0</td>\n",
       "      <td>2023-01-31 15:21:39.078837</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.0</td>\n",
       "      <td>30154.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.714909</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16</td>\n",
       "      <td>652.0</td>\n",
       "      <td>8</td>\n",
       "      <td>849.0</td>\n",
       "      <td>2023-11-26 15:21:39.078837</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.0</td>\n",
       "      <td>48371.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.346926</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>330.0</td>\n",
       "      <td>7</td>\n",
       "      <td>927.0</td>\n",
       "      <td>2023-02-27 15:21:39.078837</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.0</td>\n",
       "      <td>54174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.659499</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>575.0</td>\n",
       "      <td>8</td>\n",
       "      <td>303.0</td>\n",
       "      <td>2020-11-25 15:21:39.078837</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Annual Income  Number of Dependents  Health Score  Previous Claims  \\\n",
       "0  56.0        99990.0                   1.0     31.074627              1.0   \n",
       "1  46.0         2867.0                   1.0     50.271335              1.0   \n",
       "2  32.0        30154.0                   3.0     14.714909              2.0   \n",
       "3  60.0        48371.0                   0.0     25.346926              1.0   \n",
       "4  25.0        54174.0                   0.0      6.659499              1.0   \n",
       "\n",
       "   Vehicle Age  Credit Score  Insurance Duration  Premium Amount  \\\n",
       "0           13         320.0                   5           308.0   \n",
       "1            3         694.0                   4           517.0   \n",
       "2           16         652.0                   8           849.0   \n",
       "3           11         330.0                   7           927.0   \n",
       "4            9         575.0                   8           303.0   \n",
       "\n",
       "           Policy Start Date  ...  Policy Type_premium  \\\n",
       "0 2022-12-10 15:21:39.078837  ...                False   \n",
       "1 2023-01-31 15:21:39.078837  ...                False   \n",
       "2 2023-11-26 15:21:39.078837  ...                False   \n",
       "3 2023-02-27 15:21:39.078837  ...                False   \n",
       "4 2020-11-25 15:21:39.078837  ...                False   \n",
       "\n",
       "   Customer Feedback_good  Customer Feedback_poor  Customer Feedback_single  \\\n",
       "0                   False                    True                     False   \n",
       "1                    True                   False                     False   \n",
       "2                   False                    True                     False   \n",
       "3                   False                    True                     False   \n",
       "4                   False                    True                     False   \n",
       "\n",
       "   Smoking Status_yes  Exercise Frequency_monthly  Exercise Frequency_rarely  \\\n",
       "0                True                       False                      False   \n",
       "1                True                        True                      False   \n",
       "2               False                        True                      False   \n",
       "3               False                       False                       True   \n",
       "4               False                       False                       True   \n",
       "\n",
       "   Exercise Frequency_weekly  Property Type_condo  Property Type_house  \n",
       "0                      False                 True                False  \n",
       "1                      False                False                 True  \n",
       "2                      False                False                 True  \n",
       "3                      False                 True                False  \n",
       "4                      False                 True                False  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 278860 entries, 0 to 278859\n",
      "Data columns (total 35 columns):\n",
      " #   Column                       Non-Null Count   Dtype         \n",
      "---  ------                       --------------   -----         \n",
      " 0   Age                          278860 non-null  float64       \n",
      " 1   Annual Income                278860 non-null  float64       \n",
      " 2   Number of Dependents         278860 non-null  float64       \n",
      " 3   Health Score                 278860 non-null  float64       \n",
      " 4   Previous Claims              278860 non-null  float64       \n",
      " 5   Vehicle Age                  278860 non-null  int64         \n",
      " 6   Credit Score                 278860 non-null  float64       \n",
      " 7   Insurance Duration           278860 non-null  int64         \n",
      " 8   Premium Amount               278860 non-null  float64       \n",
      " 9   Policy Start Date            278860 non-null  datetime64[ns]\n",
      " 10  Premium Amount_log           278860 non-null  float64       \n",
      " 11  Previous Claims_log          278860 non-null  float64       \n",
      " 12  Annual Income_log            278860 non-null  float64       \n",
      " 13  Gender_male                  278860 non-null  bool          \n",
      " 14  Marital Status_married       278860 non-null  bool          \n",
      " 15  Marital Status_single        278860 non-null  bool          \n",
      " 16  Education Level_high school  278860 non-null  bool          \n",
      " 17  Education Level_master's     278860 non-null  bool          \n",
      " 18  Education Level_phd          278860 non-null  bool          \n",
      " 19  Occupation_self-employed     278860 non-null  bool          \n",
      " 20  Occupation_single            278860 non-null  bool          \n",
      " 21  Occupation_unemployed        278860 non-null  bool          \n",
      " 22  Location_suburban            278860 non-null  bool          \n",
      " 23  Location_urban               278860 non-null  bool          \n",
      " 24  Policy Type_comprehensive    278860 non-null  bool          \n",
      " 25  Policy Type_premium          278860 non-null  bool          \n",
      " 26  Customer Feedback_good       278860 non-null  bool          \n",
      " 27  Customer Feedback_poor       278860 non-null  bool          \n",
      " 28  Customer Feedback_single     278860 non-null  bool          \n",
      " 29  Smoking Status_yes           278860 non-null  bool          \n",
      " 30  Exercise Frequency_monthly   278860 non-null  bool          \n",
      " 31  Exercise Frequency_rarely    278860 non-null  bool          \n",
      " 32  Exercise Frequency_weekly    278860 non-null  bool          \n",
      " 33  Property Type_condo          278860 non-null  bool          \n",
      " 34  Property Type_house          278860 non-null  bool          \n",
      "dtypes: bool(22), datetime64[ns](1), float64(10), int64(2)\n",
      "memory usage: 33.5 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Identify categorical columns\n",
    "categorical_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Apply one-hot encoding to all categorical columns\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Display the head and info of the updated DataFrame\n",
    "display(df_encoded.head())\n",
    "display(df_encoded.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f4a240-22ef-4a46-b35f-b322b086d66b",
   "metadata": {},
   "source": [
    "Adding new features for proper training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "887fae05-11d4-4294-865d-563b781a62c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Policy_Start_Year</th>\n",
       "      <th>Policy_Start_Month</th>\n",
       "      <th>Policy_Start_Day</th>\n",
       "      <th>Age_Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>45-59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>45-59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>30-44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>60+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>18-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Policy_Start_Year  Policy_Start_Month  Policy_Start_Day Age_Group\n",
       "0               2022                  12                10     45-59\n",
       "1               2023                   1                31     45-59\n",
       "2               2023                  11                26     30-44\n",
       "3               2023                   2                27       60+\n",
       "4               2020                  11                25     18-29"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract year, month, and day from 'Policy Start Date'\n",
    "df_encoded['Policy_Start_Year'] = df_encoded['Policy Start Date'].dt.year\n",
    "df_encoded['Policy_Start_Month'] = df_encoded['Policy Start Date'].dt.month\n",
    "df_encoded['Policy_Start_Day'] = df_encoded['Policy Start Date'].dt.day\n",
    "\n",
    "# Create 'Age Group' bins from the 'Age' column\n",
    "# Define bins and labels for age groups\n",
    "age_bins = [0, 18, 30, 45, 60, 100]\n",
    "age_labels = ['0-17', '18-29', '30-44', '45-59', '60+']\n",
    "df_encoded['Age_Group'] = pd.cut(df_encoded['Age'], bins=age_bins, labels=age_labels, right=False)\n",
    "\n",
    "# Display the head of the DataFrame with the new features\n",
    "display(df_encoded[['Policy_Start_Year', 'Policy_Start_Month', 'Policy_Start_Day', 'Age_Group']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb870fa-cd7b-4053-80dc-02dbe3903c92",
   "metadata": {},
   "source": [
    "Check for need for text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93efe643-ccd6-4ef0-9d3f-3644e8769c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in df_encoded:\n",
      "Index(['Age', 'Annual Income', 'Number of Dependents', 'Health Score',\n",
      "       'Previous Claims', 'Vehicle Age', 'Credit Score', 'Insurance Duration',\n",
      "       'Premium Amount', 'Policy Start Date', 'Premium Amount_log',\n",
      "       'Previous Claims_log', 'Annual Income_log', 'Gender_male',\n",
      "       'Marital Status_married', 'Marital Status_single',\n",
      "       'Education Level_high school', 'Education Level_master's',\n",
      "       'Education Level_phd', 'Occupation_self-employed', 'Occupation_single',\n",
      "       'Occupation_unemployed', 'Location_suburban', 'Location_urban',\n",
      "       'Policy Type_comprehensive', 'Policy Type_premium',\n",
      "       'Customer Feedback_good', 'Customer Feedback_poor',\n",
      "       'Customer Feedback_single', 'Smoking Status_yes',\n",
      "       'Exercise Frequency_monthly', 'Exercise Frequency_rarely',\n",
      "       'Exercise Frequency_weekly', 'Property Type_condo',\n",
      "       'Property Type_house', 'Policy_Start_Year', 'Policy_Start_Month',\n",
      "       'Policy_Start_Day', 'Age_Group'],\n",
      "      dtype='object')\n",
      "\n",
      "No text columns remaining in df_encoded that require further processing.\n"
     ]
    }
   ],
   "source": [
    "# Examine the columns in the df_encoded DataFrame\n",
    "print(\"Columns in df_encoded:\")\n",
    "print(df_encoded.columns)\n",
    "\n",
    "# Check if there are any text columns left that might require text processing\n",
    "# after initial cleaning and one-hot encoding\n",
    "text_columns_remaining = df_encoded.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "if text_columns_remaining:\n",
    "    print(\"\\nRemaining text columns that might require further processing:\")\n",
    "    print(text_columns_remaining)\n",
    "    # Outline potential steps if needed (not executing code here as per instruction)\n",
    "    print(\"\\nFurther text data processing steps (if required for these columns):\")\n",
    "    print(\"1. Examine the content of these text columns to understand their nature.\")\n",
    "    print(\"2. If they contain free-form text, consider techniques like TF-IDF, Word Embeddings (e.g., Word2Vec, GloVe), or pre-trained transformer models (e.g., BERT) for feature extraction.\")\n",
    "    print(\"3. If they are structured text with specific patterns, consider using regular expressions or custom parsing functions.\")\n",
    "    print(\"4. Based on the chosen technique, implement the appropriate code to transform the text data into numerical features.\")\n",
    "else:\n",
    "    print(\"\\nNo text columns remaining in df_encoded that require further processing.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceba4747-0152-46bb-ae5d-d20f241fe8ca",
   "metadata": {},
   "source": [
    "Separate features (X) and target variable (y), and split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd766b25-be72-465f-883b-a90839bcfd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (209145, 33)\n",
      "Shape of X_test: (69715, 33)\n",
      "Shape of y_train: (209145,)\n",
      "Shape of y_test: (69715,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 1. Define the features X by dropping the 'Premium Amount' column and other irrelevant columns.\n",
    "# 'Policy Start Date' is a datetime object, and 'Age_Group' is an object (categorical)\n",
    "# We will drop the original 'Premium Amount' and the transformed log columns for now, focusing on the original numerical features and one-hot encoded features.\n",
    "columns_to_drop = ['Premium Amount', 'Policy Start Date', 'Age_Group', 'Premium Amount_log', 'Previous Claims_log', 'Annual Income_log']\n",
    "X = df_encoded.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# 2. Define the target variable y as the 'Premium Amount' column.\n",
    "y = df_encoded['Premium Amount']\n",
    "\n",
    "# 3. Split the data into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# 4. Print the shapes of the resulting training and testing sets.\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2a242b-af00-4138-840f-6edcfbedda85",
   "metadata": {},
   "source": [
    "Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3423be29-0c1d-48b1-8356-0dfb8362c31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 Most Important Features:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Health Score                 0.125994\n",
       "Annual Income                0.125078\n",
       "Credit Score                 0.107163\n",
       "Age                          0.082520\n",
       "Policy_Start_Day             0.075037\n",
       "Vehicle Age                  0.068166\n",
       "Policy_Start_Month           0.052050\n",
       "Insurance Duration           0.045089\n",
       "Policy_Start_Year            0.036087\n",
       "Number of Dependents         0.032477\n",
       "Previous Claims              0.027181\n",
       "Gender_male                  0.012380\n",
       "Smoking Status_yes           0.011930\n",
       "Policy Type_comprehensive    0.010934\n",
       "Marital Status_single        0.010932\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instantiate a RandomForestRegressor model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "# Create a pandas Series for better visualization\n",
    "feature_importance_series = pd.Series(feature_importances, index=X_train.columns)\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "sorted_feature_importances = feature_importance_series.sort_values(ascending=False)\n",
    "\n",
    "# Display the top 15 most important features\n",
    "top_n = 15\n",
    "print(f\"Top {top_n} Most Important Features:\")\n",
    "display(sorted_feature_importances.head(top_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9a3393-69d3-4a12-81b2-ebaf61c7d510",
   "metadata": {},
   "source": [
    "Feature selection based on importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf3a112e-1b72-4aa3-9bdf-68fe5c4e3a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features (20):\n",
      "['Health Score', 'Annual Income', 'Credit Score', 'Age', 'Policy_Start_Day', 'Vehicle Age', 'Policy_Start_Month', 'Insurance Duration', 'Policy_Start_Year', 'Number of Dependents', 'Previous Claims', 'Gender_male', 'Smoking Status_yes', 'Policy Type_comprehensive', 'Marital Status_single', 'Location_suburban', 'Policy Type_premium', 'Marital Status_married', 'Property Type_house', 'Occupation_single']\n",
      "\n",
      "Shape of X_train after feature selection: (209145, 20)\n",
      "Shape of X_test after feature selection: (69715, 20)\n"
     ]
    }
   ],
   "source": [
    "# 1. Based on the sorted_feature_importances series, decide on a number of top features to keep.\n",
    "# Let's choose to keep the top 20 features as a starting point.\n",
    "num_top_features = 20\n",
    "selected_features = sorted_feature_importances.head(num_top_features).index.tolist()\n",
    "\n",
    "# 2. Create a list of the selected feature names.\n",
    "print(f\"Selected Features ({num_top_features}):\")\n",
    "print(selected_features)\n",
    "\n",
    "# 3. Filter the training and testing feature DataFrames (X_train and X_test) to include only the selected features.\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "# 4. Print the shapes of the filtered X_train and X_test to confirm the feature selection.\n",
    "print(\"\\nShape of X_train after feature selection:\", X_train_selected.shape)\n",
    "print(\"Shape of X_test after feature selection:\", X_test_selected.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de8c468-df25-4557-a2c8-d99e170303d3",
   "metadata": {},
   "source": [
    "Experimenting with different regression algorithym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7cb20767-2ac1-462a-85ca-1d725852e1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Models:\n",
      "Training Linear Regression...\n",
      "Linear Regression training completed.\n",
      "Training Ridge...\n",
      "Ridge training completed.\n",
      "Training Lasso...\n",
      "Lasso training completed.\n",
      "Training Elastic Net...\n",
      "Elastic Net training completed.\n",
      "Training Decision Tree Regressor...\n",
      "Decision Tree Regressor training completed.\n",
      "Training Random Forest Regressor...\n",
      "Random Forest Regressor training completed.\n",
      "Training Gradient Boosting Regressor...\n",
      "Gradient Boosting Regressor training completed.\n",
      "Training Support Vector Regressor...\n",
      "Support Vector Regressor training completed.\n",
      "Training K-Neighbors Regressor...\n",
      "K-Neighbors Regressor training completed.\n",
      "\n",
      "All specified models have been attempted for training.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Create a dictionary to store the instantiated models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(random_state=42),\n",
    "    \"Lasso\": Lasso(random_state=42),\n",
    "    \"Elastic Net\": ElasticNet(random_state=42),\n",
    "    \"Decision Tree Regressor\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(random_state=42),\n",
    "    \"Gradient Boosting Regressor\": GradientBoostingRegressor(random_state=42),\n",
    "    \"Support Vector Regressor\": SVR(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor()\n",
    "}\n",
    "\n",
    "# Dictionary to store trained models\n",
    "trained_models = {}\n",
    "\n",
    "# Iterate through the models and train them\n",
    "print(\"Training Models:\")\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    try:\n",
    "        model.fit(X_train_selected, y_train)\n",
    "        trained_models[name] = model\n",
    "        print(f\"{name} training completed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error training {name}: {e}\")\n",
    "\n",
    "print(\"\\nAll specified models have been attempted for training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cc8544-be01-42f5-9dbb-0ebe2adb923f",
   "metadata": {},
   "source": [
    "Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04d8f042-c6b0-4e46-8e3b-b3982987b55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Models for Hyperparameter Tuning Model Selection:\n",
      "Evaluating Linear Regression...\n",
      "Linear Regression evaluation completed.\n",
      "Evaluating Ridge...\n",
      "Ridge evaluation completed.\n",
      "Evaluating Lasso...\n",
      "Lasso evaluation completed.\n",
      "Evaluating Elastic Net...\n",
      "Elastic Net evaluation completed.\n",
      "Evaluating Decision Tree Regressor...\n",
      "Decision Tree Regressor evaluation completed.\n",
      "Evaluating Random Forest Regressor...\n",
      "Random Forest Regressor evaluation completed.\n",
      "Evaluating Gradient Boosting Regressor...\n",
      "Gradient Boosting Regressor evaluation completed.\n",
      "Evaluating Support Vector Regressor...\n",
      "Support Vector Regressor evaluation completed.\n",
      "Evaluating K-Neighbors Regressor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EAC\\anaconda\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\EAC\\anaconda\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\EAC\\anaconda\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\EAC\\anaconda\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Users\\EAC\\anaconda\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Neighbors Regressor evaluation completed.\n",
      "\n",
      "Initial Model Evaluation Results for Tuning Selection:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R-squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>693.342222</td>\n",
       "      <td>8.172998e+05</td>\n",
       "      <td>-0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Elastic Net</th>\n",
       "      <td>693.344722</td>\n",
       "      <td>8.173050e+05</td>\n",
       "      <td>-0.000056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>693.363451</td>\n",
       "      <td>8.173589e+05</td>\n",
       "      <td>-0.000121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>693.363452</td>\n",
       "      <td>8.173589e+05</td>\n",
       "      <td>-0.000121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting Regressor</th>\n",
       "      <td>693.401282</td>\n",
       "      <td>8.174986e+05</td>\n",
       "      <td>-0.000292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Regressor</th>\n",
       "      <td>721.056510</td>\n",
       "      <td>8.422479e+05</td>\n",
       "      <td>-0.030576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Regressor</th>\n",
       "      <td>655.533656</td>\n",
       "      <td>8.917774e+05</td>\n",
       "      <td>-0.091180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Neighbors Regressor</th>\n",
       "      <td>754.493552</td>\n",
       "      <td>9.858998e+05</td>\n",
       "      <td>-0.206348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Regressor</th>\n",
       "      <td>978.238342</td>\n",
       "      <td>1.773784e+06</td>\n",
       "      <td>-1.170404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    MAE           MSE  R-squared\n",
       "Lasso                        693.342222  8.172998e+05  -0.000049\n",
       "Elastic Net                  693.344722  8.173050e+05  -0.000056\n",
       "Ridge                        693.363451  8.173589e+05  -0.000121\n",
       "Linear Regression            693.363452  8.173589e+05  -0.000121\n",
       "Gradient Boosting Regressor  693.401282  8.174986e+05  -0.000292\n",
       "Random Forest Regressor      721.056510  8.422479e+05  -0.030576\n",
       "Support Vector Regressor     655.533656  8.917774e+05  -0.091180\n",
       "K-Neighbors Regressor        754.493552  9.858998e+05  -0.206348\n",
       "Decision Tree Regressor      978.238342  1.773784e+06  -1.170404"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top models selected for hyperparameter tuning: ['Lasso', 'Elastic Net', 'Ridge']\n",
      "\n",
      "Performing hyperparameter tuning for Lasso...\n",
      "Skipping tuning for Lasso as no parameter grid is defined.\n",
      "\n",
      "Performing hyperparameter tuning for Elastic Net...\n",
      "Skipping tuning for Elastic Net as no parameter grid is defined.\n",
      "\n",
      "Performing hyperparameter tuning for Ridge...\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Best parameters for Ridge: {'alpha': 10.0}\n",
      "Best R-squared for Ridge: -0.0002\n",
      "\n",
      "Hyperparameter tuning completed for selected models.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge # Including Ridge as it often performs well\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# Dictionary to store evaluation results\n",
    "evaluation_results = {}\n",
    "\n",
    "# Evaluate the trained models first to get evaluation_df\n",
    "print(\"Evaluating Models for Hyperparameter Tuning Model Selection:\")\n",
    "for name, model in trained_models.items():\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    try:\n",
    "        # Make predictions on the testing data\n",
    "        y_pred = model.predict(X_test_selected)\n",
    "\n",
    "        # Calculate evaluation metrics\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        # Store the results\n",
    "        evaluation_results[name] = {\n",
    "            'MAE': mae,\n",
    "            'MSE': mse,\n",
    "            'R-squared': r2\n",
    "        }\n",
    "        print(f\"{name} evaluation completed.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating {name}: {e}\")\n",
    "\n",
    "# Create evaluation_df\n",
    "evaluation_df = pd.DataFrame(evaluation_results).T\n",
    "print(\"\\nInitial Model Evaluation Results for Tuning Selection:\")\n",
    "display(evaluation_df.sort_values(by='R-squared', ascending=False))\n",
    "\n",
    "\n",
    "# Identify the best performing models based on R-squared from the previous evaluation\n",
    "# Let's select the top 3 models for hyperparameter tuning\n",
    "top_models = evaluation_df.sort_values(by='R-squared', ascending=False).head(3).index.tolist()\n",
    "print(f\"Top models selected for hyperparameter tuning: {top_models}\")\n",
    "\n",
    "tuned_models = {}\n",
    "\n",
    "for model_name in top_models:\n",
    "    print(f\"\\nPerforming hyperparameter tuning for {model_name}...\")\n",
    "\n",
    "    # Define parameter grids for each model\n",
    "    param_grid = {}\n",
    "    model = None\n",
    "\n",
    "    if model_name == \"Random Forest Regressor\":\n",
    "        model = RandomForestRegressor(random_state=42)\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200],\n",
    "            'max_depth': [10, 20, None],\n",
    "            'min_samples_split': [2, 5],\n",
    "            'min_samples_leaf': [1, 2]\n",
    "        }\n",
    "    elif model_name == \"Gradient Boosting Regressor\":\n",
    "        model = GradientBoostingRegressor(random_state=42)\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200],\n",
    "            'learning_rate': [0.01, 0.1],\n",
    "            'max_depth': [3, 5],\n",
    "            'min_samples_split': [2, 5],\n",
    "            'min_samples_leaf': [1, 2]\n",
    "        }\n",
    "    elif model_name == \"Support Vector Regressor\":\n",
    "        model = SVR()\n",
    "        # SVR can be computationally expensive, use a smaller subset of data or a simpler grid for initial tuning\n",
    "        param_grid = {\n",
    "            'C': [0.1, 1],\n",
    "            'epsilon': [0.1, 0.2],\n",
    "            'kernel': ['rbf']\n",
    "        }\n",
    "        # For SVR, consider using a smaller sample of the training data if it takes too long\n",
    "        # X_train_subset, _, y_train_subset, _ = train_test_split(X_train_selected, y_train, train_size=0.1, random_state=42)\n",
    "        # print(f\"Using a subset of training data ({X_train_subset.shape[0]} samples) for SVR tuning.\")\n",
    "        # X_train_tuned = X_train_subset\n",
    "        # y_train_tuned = y_train_subset\n",
    "        X_train_tuned = X_train_selected # Use full data for now\n",
    "        y_train_tuned = y_train # Use full data for now\n",
    "\n",
    "    elif model_name == \"Ridge\":\n",
    "        model = Ridge(random_state=42)\n",
    "        param_grid = {\n",
    "            'alpha': [0.1, 1.0, 10.0]\n",
    "        }\n",
    "        X_train_tuned = X_train_selected\n",
    "        y_train_tuned = y_train\n",
    "\n",
    "    else:\n",
    "        print(f\"Skipping tuning for {model_name} as no parameter grid is defined.\")\n",
    "        continue\n",
    "\n",
    "    if model is not None and param_grid:\n",
    "        # Set up GridSearchCV\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=3, scoring='r2', n_jobs=-1, verbose=1)\n",
    "\n",
    "        try:\n",
    "            # Perform the grid search\n",
    "            if model_name == \"Support Vector Regressor\":\n",
    "                 grid_search.fit(X_train_tuned, y_train_tuned)\n",
    "            else:\n",
    "                 grid_search.fit(X_train_selected, y_train)\n",
    "\n",
    "\n",
    "            # Store the best model and its parameters\n",
    "            tuned_models[model_name] = grid_search.best_estimator_\n",
    "            print(f\"Best parameters for {model_name}: {grid_search.best_params_}\")\n",
    "            print(f\"Best R-squared for {model_name}: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during GridSearchCV for {model_name}: {e}\")\n",
    "\n",
    "print(\"\\nHyperparameter tuning completed for selected models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635b7c9c-9aa5-47be-81b7-f5bca271472f",
   "metadata": {},
   "source": [
    "Save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a4a1981-02bd-47b7-ae1d-7e1178ce1faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model ('Ridge') saved to 'ridge_best_model.pkl' successfully.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming 'tuned_models' is a dictionary containing the best trained models after tuning\n",
    "# and you want to save the best performing one based on some criteria (e.g., R-squared).\n",
    "# In the previous cell, only Ridge was tuned. Let's select Ridge as the best tuned model for saving.\n",
    "if 'Ridge' in tuned_models:\n",
    "    best_model_name = 'Ridge'\n",
    "    best_model = tuned_models['Ridge']\n",
    "\n",
    "    # Define the filename for the best model\n",
    "    best_model_filename = f\"{best_model_name.replace(' ', '_').lower()}_best_model.pkl\"\n",
    "\n",
    "    # Save the best model to a .pkl file\n",
    "    try:\n",
    "        with open(best_model_filename, 'wb') as f:\n",
    "            pickle.dump(best_model, f)\n",
    "        print(f\"Best model ('{best_model_name}') saved to '{best_model_filename}' successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving the best model: {e}\")\n",
    "else:\n",
    "    print(\"Ridge model was not found in tuned_models. Cannot save the best model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f77c63-e183-4e27-9530-5f90fb6e7d52",
   "metadata": {},
   "source": [
    "Save the processed dataset (including engineered features) to an Excel file for download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8c3e442-d6c2-4565-8083-e9c06b100065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed dataset saved to 'processed_insurance_premium_data.xlsx' successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save the processed DataFrame to an Excel file\n",
    "output_excel_file = \"processed_insurance_premium_data.xlsx\"\n",
    "try:\n",
    "    df_encoded.to_excel(output_excel_file, index=False)\n",
    "    print(f\"Processed dataset saved to '{output_excel_file}' successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving processed dataset to Excel: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
